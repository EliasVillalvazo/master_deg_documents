{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOnOy3FY3/3pKh17UsU2z+I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EliasVillalvazo/master_deg_documents/blob/main/pytorch_tutorial/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolution Neural Networks\n",
        "\n",
        "Made of neurons as well\n",
        "They work on image data and work on images. Their purpose is to learn some features from the images and then perform the classification task\n",
        "\n",
        "# Max Pooling\n",
        "Downsample an images by applying a max filter to subregions of the image. The maximum value is kept\n",
        "\n",
        "Reduces the computational cost by reducing the size (parameters to learn) and helps to avoid overfitting.\n",
        "\n",
        "\n",
        "# Size after a convolution:\n",
        "\n",
        "(W - F + 2P) / S + 1\n",
        "W = Width\n",
        "F = Filter size\n",
        "P = Padding\n",
        "S = Stride"
      ],
      "metadata": {
        "id": "TnY3nQOD-xzr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bfZYrZ0h-tE0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# hyperparameters\n",
        "num_epochs = 4\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n",
        "\n",
        "# define transformations\n",
        "\n",
        "transform = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "metadata": {
        "id": "FszEGKS0AlS8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='.', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='.', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgmj70VEBdxT",
        "outputId": "064aded4-6edf-4b8f-912d-e1467a0dcc58"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "EgIMmWOwDWm3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, stride=2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc = nn.Linear(16*5*5, 120) # 16 channels multiplied by the width and length of the image after convolutions and pooling. Apply the formula\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16*5*5)\n",
        "    x = F.relu(self.fc(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "model = ConvNet().to(device)"
      ],
      "metadata": {
        "id": "B17V4QbXEXIx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create loss and optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "kn4lBWxXDkAu"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do training loop now\n",
        "\n",
        "# define number of total steps\n",
        "n_total_steps = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  # loop over the batches\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    # reshape images first and send to device\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "    # backprop\n",
        "    loss.backward()\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i + 1) % 100 == 0:\n",
        "      print(f'current epoch: {epoch+1} / {num_epochs}; current step: {i+1} / {n_total_steps}; loss = {loss.item():.4f}')\n",
        "\n",
        "# test step\n",
        "with torch.no_grad():\n",
        "  n_correct_predictions = 0\n",
        "  n_samples = 0\n",
        "  for images, labels in test_loader:\n",
        "    # reshape images first and send to device\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # calculate the predictions\n",
        "    output_t = model(images)\n",
        "    _, predictions = torch.max(output_t, 1) # returns value and index\n",
        "    n_samples += labels.shape[0]\n",
        "    n_correct_predictions += (predictions == labels).sum().item()\n",
        "\n",
        "  acc = 100.0 * n_correct_predictions / n_samples\n",
        "  print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWraFdGMEgSY",
        "outputId": "e556b3ec-4ca4-448c-cbf8-372c0e8e7a6f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current epoch: 1 / 4; current step: 100 / 12500; loss = 2.3015\n",
            "current epoch: 1 / 4; current step: 200 / 12500; loss = 2.3656\n",
            "current epoch: 1 / 4; current step: 300 / 12500; loss = 2.2971\n",
            "current epoch: 1 / 4; current step: 400 / 12500; loss = 2.3079\n",
            "current epoch: 1 / 4; current step: 500 / 12500; loss = 2.2690\n",
            "current epoch: 1 / 4; current step: 600 / 12500; loss = 2.3110\n",
            "current epoch: 1 / 4; current step: 700 / 12500; loss = 2.3249\n",
            "current epoch: 1 / 4; current step: 800 / 12500; loss = 2.3208\n",
            "current epoch: 1 / 4; current step: 900 / 12500; loss = 2.3130\n",
            "current epoch: 1 / 4; current step: 1000 / 12500; loss = 2.2927\n",
            "current epoch: 1 / 4; current step: 1100 / 12500; loss = 2.2707\n",
            "current epoch: 1 / 4; current step: 1200 / 12500; loss = 2.3389\n",
            "current epoch: 1 / 4; current step: 1300 / 12500; loss = 2.2820\n",
            "current epoch: 1 / 4; current step: 1400 / 12500; loss = 2.3070\n",
            "current epoch: 1 / 4; current step: 1500 / 12500; loss = 2.3200\n",
            "current epoch: 1 / 4; current step: 1600 / 12500; loss = 2.3294\n",
            "current epoch: 1 / 4; current step: 1700 / 12500; loss = 2.2879\n",
            "current epoch: 1 / 4; current step: 1800 / 12500; loss = 2.2968\n",
            "current epoch: 1 / 4; current step: 1900 / 12500; loss = 2.2958\n",
            "current epoch: 1 / 4; current step: 2000 / 12500; loss = 2.3538\n",
            "current epoch: 1 / 4; current step: 2100 / 12500; loss = 2.3347\n",
            "current epoch: 1 / 4; current step: 2200 / 12500; loss = 2.2783\n",
            "current epoch: 1 / 4; current step: 2300 / 12500; loss = 2.3557\n",
            "current epoch: 1 / 4; current step: 2400 / 12500; loss = 2.3508\n",
            "current epoch: 1 / 4; current step: 2500 / 12500; loss = 2.2875\n",
            "current epoch: 1 / 4; current step: 2600 / 12500; loss = 2.2843\n",
            "current epoch: 1 / 4; current step: 2700 / 12500; loss = 2.3481\n",
            "current epoch: 1 / 4; current step: 2800 / 12500; loss = 2.2711\n",
            "current epoch: 1 / 4; current step: 2900 / 12500; loss = 2.3525\n",
            "current epoch: 1 / 4; current step: 3000 / 12500; loss = 2.2809\n",
            "current epoch: 1 / 4; current step: 3100 / 12500; loss = 2.2853\n",
            "current epoch: 1 / 4; current step: 3200 / 12500; loss = 2.3055\n",
            "current epoch: 1 / 4; current step: 3300 / 12500; loss = 2.2963\n",
            "current epoch: 1 / 4; current step: 3400 / 12500; loss = 2.3199\n",
            "current epoch: 1 / 4; current step: 3500 / 12500; loss = 2.3061\n",
            "current epoch: 1 / 4; current step: 3600 / 12500; loss = 2.2915\n",
            "current epoch: 1 / 4; current step: 3700 / 12500; loss = 2.3145\n",
            "current epoch: 1 / 4; current step: 3800 / 12500; loss = 2.3255\n",
            "current epoch: 1 / 4; current step: 3900 / 12500; loss = 2.3073\n",
            "current epoch: 1 / 4; current step: 4000 / 12500; loss = 2.3395\n",
            "current epoch: 1 / 4; current step: 4100 / 12500; loss = 2.2942\n",
            "current epoch: 1 / 4; current step: 4200 / 12500; loss = 2.2998\n",
            "current epoch: 1 / 4; current step: 4300 / 12500; loss = 2.2933\n",
            "current epoch: 1 / 4; current step: 4400 / 12500; loss = 2.3080\n",
            "current epoch: 1 / 4; current step: 4500 / 12500; loss = 2.3286\n",
            "current epoch: 1 / 4; current step: 4600 / 12500; loss = 2.2916\n",
            "current epoch: 1 / 4; current step: 4700 / 12500; loss = 2.3080\n",
            "current epoch: 1 / 4; current step: 4800 / 12500; loss = 2.3159\n",
            "current epoch: 1 / 4; current step: 4900 / 12500; loss = 2.2987\n",
            "current epoch: 1 / 4; current step: 5000 / 12500; loss = 2.2950\n",
            "current epoch: 1 / 4; current step: 5100 / 12500; loss = 2.3028\n",
            "current epoch: 1 / 4; current step: 5200 / 12500; loss = 2.3066\n",
            "current epoch: 1 / 4; current step: 5300 / 12500; loss = 2.3270\n",
            "current epoch: 1 / 4; current step: 5400 / 12500; loss = 2.2970\n",
            "current epoch: 1 / 4; current step: 5500 / 12500; loss = 2.3070\n",
            "current epoch: 1 / 4; current step: 5600 / 12500; loss = 2.2969\n",
            "current epoch: 1 / 4; current step: 5700 / 12500; loss = 2.3255\n",
            "current epoch: 1 / 4; current step: 5800 / 12500; loss = 2.3294\n",
            "current epoch: 1 / 4; current step: 5900 / 12500; loss = 2.2995\n",
            "current epoch: 1 / 4; current step: 6000 / 12500; loss = 2.3029\n",
            "current epoch: 1 / 4; current step: 6100 / 12500; loss = 2.3025\n",
            "current epoch: 1 / 4; current step: 6200 / 12500; loss = 2.2945\n",
            "current epoch: 1 / 4; current step: 6300 / 12500; loss = 2.2710\n",
            "current epoch: 1 / 4; current step: 6400 / 12500; loss = 2.2850\n",
            "current epoch: 1 / 4; current step: 6500 / 12500; loss = 2.3212\n",
            "current epoch: 1 / 4; current step: 6600 / 12500; loss = 2.2995\n",
            "current epoch: 1 / 4; current step: 6700 / 12500; loss = 2.3069\n",
            "current epoch: 1 / 4; current step: 6800 / 12500; loss = 2.3138\n",
            "current epoch: 1 / 4; current step: 6900 / 12500; loss = 2.2940\n",
            "current epoch: 1 / 4; current step: 7000 / 12500; loss = 2.3145\n",
            "current epoch: 1 / 4; current step: 7100 / 12500; loss = 2.2812\n",
            "current epoch: 1 / 4; current step: 7200 / 12500; loss = 2.2880\n",
            "current epoch: 1 / 4; current step: 7300 / 12500; loss = 2.3088\n",
            "current epoch: 1 / 4; current step: 7400 / 12500; loss = 2.2873\n",
            "current epoch: 1 / 4; current step: 7500 / 12500; loss = 2.2722\n",
            "current epoch: 1 / 4; current step: 7600 / 12500; loss = 2.2565\n",
            "current epoch: 1 / 4; current step: 7700 / 12500; loss = 2.2843\n",
            "current epoch: 1 / 4; current step: 7800 / 12500; loss = 2.2912\n",
            "current epoch: 1 / 4; current step: 7900 / 12500; loss = 2.2567\n",
            "current epoch: 1 / 4; current step: 8000 / 12500; loss = 2.2930\n",
            "current epoch: 1 / 4; current step: 8100 / 12500; loss = 2.3255\n",
            "current epoch: 1 / 4; current step: 8200 / 12500; loss = 2.2926\n",
            "current epoch: 1 / 4; current step: 8300 / 12500; loss = 2.2719\n",
            "current epoch: 1 / 4; current step: 8400 / 12500; loss = 2.2816\n",
            "current epoch: 1 / 4; current step: 8500 / 12500; loss = 2.2591\n",
            "current epoch: 1 / 4; current step: 8600 / 12500; loss = 2.2406\n",
            "current epoch: 1 / 4; current step: 8700 / 12500; loss = 2.2979\n",
            "current epoch: 1 / 4; current step: 8800 / 12500; loss = 2.2755\n",
            "current epoch: 1 / 4; current step: 8900 / 12500; loss = 2.3283\n",
            "current epoch: 1 / 4; current step: 9000 / 12500; loss = 2.2771\n",
            "current epoch: 1 / 4; current step: 9100 / 12500; loss = 2.2514\n",
            "current epoch: 1 / 4; current step: 9200 / 12500; loss = 2.2742\n",
            "current epoch: 1 / 4; current step: 9300 / 12500; loss = 2.3040\n",
            "current epoch: 1 / 4; current step: 9400 / 12500; loss = 2.2626\n",
            "current epoch: 1 / 4; current step: 9500 / 12500; loss = 2.3331\n",
            "current epoch: 1 / 4; current step: 9600 / 12500; loss = 2.2589\n",
            "current epoch: 1 / 4; current step: 9700 / 12500; loss = 2.2883\n",
            "current epoch: 1 / 4; current step: 9800 / 12500; loss = 2.2903\n",
            "current epoch: 1 / 4; current step: 9900 / 12500; loss = 2.2811\n",
            "current epoch: 1 / 4; current step: 10000 / 12500; loss = 2.3172\n",
            "current epoch: 1 / 4; current step: 10100 / 12500; loss = 2.3100\n",
            "current epoch: 1 / 4; current step: 10200 / 12500; loss = 2.2143\n",
            "current epoch: 1 / 4; current step: 10300 / 12500; loss = 2.3255\n",
            "current epoch: 1 / 4; current step: 10400 / 12500; loss = 2.2885\n",
            "current epoch: 1 / 4; current step: 10500 / 12500; loss = 2.3503\n",
            "current epoch: 1 / 4; current step: 10600 / 12500; loss = 2.2652\n",
            "current epoch: 1 / 4; current step: 10700 / 12500; loss = 2.2092\n",
            "current epoch: 1 / 4; current step: 10800 / 12500; loss = 2.3252\n",
            "current epoch: 1 / 4; current step: 10900 / 12500; loss = 2.3119\n",
            "current epoch: 1 / 4; current step: 11000 / 12500; loss = 2.1954\n",
            "current epoch: 1 / 4; current step: 11100 / 12500; loss = 2.2957\n",
            "current epoch: 1 / 4; current step: 11200 / 12500; loss = 2.3359\n",
            "current epoch: 1 / 4; current step: 11300 / 12500; loss = 2.2381\n",
            "current epoch: 1 / 4; current step: 11400 / 12500; loss = 2.2367\n",
            "current epoch: 1 / 4; current step: 11500 / 12500; loss = 2.1998\n",
            "current epoch: 1 / 4; current step: 11600 / 12500; loss = 2.1941\n",
            "current epoch: 1 / 4; current step: 11700 / 12500; loss = 2.3020\n",
            "current epoch: 1 / 4; current step: 11800 / 12500; loss = 2.2459\n",
            "current epoch: 1 / 4; current step: 11900 / 12500; loss = 2.2641\n",
            "current epoch: 1 / 4; current step: 12000 / 12500; loss = 2.2738\n",
            "current epoch: 1 / 4; current step: 12100 / 12500; loss = 2.2829\n",
            "current epoch: 1 / 4; current step: 12200 / 12500; loss = 2.1955\n",
            "current epoch: 1 / 4; current step: 12300 / 12500; loss = 2.2342\n",
            "current epoch: 1 / 4; current step: 12400 / 12500; loss = 2.3458\n",
            "current epoch: 1 / 4; current step: 12500 / 12500; loss = 2.2752\n",
            "current epoch: 2 / 4; current step: 100 / 12500; loss = 2.1005\n",
            "current epoch: 2 / 4; current step: 200 / 12500; loss = 2.3773\n",
            "current epoch: 2 / 4; current step: 300 / 12500; loss = 2.1816\n",
            "current epoch: 2 / 4; current step: 400 / 12500; loss = 2.2032\n",
            "current epoch: 2 / 4; current step: 500 / 12500; loss = 2.1565\n",
            "current epoch: 2 / 4; current step: 600 / 12500; loss = 2.2367\n",
            "current epoch: 2 / 4; current step: 700 / 12500; loss = 2.2156\n",
            "current epoch: 2 / 4; current step: 800 / 12500; loss = 2.0804\n",
            "current epoch: 2 / 4; current step: 900 / 12500; loss = 2.2227\n",
            "current epoch: 2 / 4; current step: 1000 / 12500; loss = 2.1269\n",
            "current epoch: 2 / 4; current step: 1100 / 12500; loss = 2.0372\n",
            "current epoch: 2 / 4; current step: 1200 / 12500; loss = 1.8805\n",
            "current epoch: 2 / 4; current step: 1300 / 12500; loss = 2.0857\n",
            "current epoch: 2 / 4; current step: 1400 / 12500; loss = 2.1204\n",
            "current epoch: 2 / 4; current step: 1500 / 12500; loss = 2.0120\n",
            "current epoch: 2 / 4; current step: 1600 / 12500; loss = 2.0782\n",
            "current epoch: 2 / 4; current step: 1700 / 12500; loss = 1.8354\n",
            "current epoch: 2 / 4; current step: 1800 / 12500; loss = 2.0525\n",
            "current epoch: 2 / 4; current step: 1900 / 12500; loss = 1.7264\n",
            "current epoch: 2 / 4; current step: 2000 / 12500; loss = 2.1641\n",
            "current epoch: 2 / 4; current step: 2100 / 12500; loss = 1.6521\n",
            "current epoch: 2 / 4; current step: 2200 / 12500; loss = 2.1731\n",
            "current epoch: 2 / 4; current step: 2300 / 12500; loss = 1.9672\n",
            "current epoch: 2 / 4; current step: 2400 / 12500; loss = 2.1630\n",
            "current epoch: 2 / 4; current step: 2500 / 12500; loss = 2.3210\n",
            "current epoch: 2 / 4; current step: 2600 / 12500; loss = 2.1542\n",
            "current epoch: 2 / 4; current step: 2700 / 12500; loss = 2.0316\n",
            "current epoch: 2 / 4; current step: 2800 / 12500; loss = 1.9274\n",
            "current epoch: 2 / 4; current step: 2900 / 12500; loss = 1.7733\n",
            "current epoch: 2 / 4; current step: 3000 / 12500; loss = 1.8285\n",
            "current epoch: 2 / 4; current step: 3100 / 12500; loss = 1.7787\n",
            "current epoch: 2 / 4; current step: 3200 / 12500; loss = 2.0929\n",
            "current epoch: 2 / 4; current step: 3300 / 12500; loss = 1.9680\n",
            "current epoch: 2 / 4; current step: 3400 / 12500; loss = 1.8236\n",
            "current epoch: 2 / 4; current step: 3500 / 12500; loss = 2.4218\n",
            "current epoch: 2 / 4; current step: 3600 / 12500; loss = 2.5113\n",
            "current epoch: 2 / 4; current step: 3700 / 12500; loss = 1.6949\n",
            "current epoch: 2 / 4; current step: 3800 / 12500; loss = 1.8607\n",
            "current epoch: 2 / 4; current step: 3900 / 12500; loss = 2.3609\n",
            "current epoch: 2 / 4; current step: 4000 / 12500; loss = 2.2320\n",
            "current epoch: 2 / 4; current step: 4100 / 12500; loss = 1.6899\n",
            "current epoch: 2 / 4; current step: 4200 / 12500; loss = 2.1141\n",
            "current epoch: 2 / 4; current step: 4300 / 12500; loss = 2.0728\n",
            "current epoch: 2 / 4; current step: 4400 / 12500; loss = 2.2573\n",
            "current epoch: 2 / 4; current step: 4500 / 12500; loss = 2.2207\n",
            "current epoch: 2 / 4; current step: 4600 / 12500; loss = 1.5575\n",
            "current epoch: 2 / 4; current step: 4700 / 12500; loss = 2.3076\n",
            "current epoch: 2 / 4; current step: 4800 / 12500; loss = 1.4360\n",
            "current epoch: 2 / 4; current step: 4900 / 12500; loss = 2.1579\n",
            "current epoch: 2 / 4; current step: 5000 / 12500; loss = 1.9580\n",
            "current epoch: 2 / 4; current step: 5100 / 12500; loss = 1.8327\n",
            "current epoch: 2 / 4; current step: 5200 / 12500; loss = 1.6720\n",
            "current epoch: 2 / 4; current step: 5300 / 12500; loss = 1.7294\n",
            "current epoch: 2 / 4; current step: 5400 / 12500; loss = 1.4199\n",
            "current epoch: 2 / 4; current step: 5500 / 12500; loss = 1.9943\n",
            "current epoch: 2 / 4; current step: 5600 / 12500; loss = 1.8533\n",
            "current epoch: 2 / 4; current step: 5700 / 12500; loss = 2.0365\n",
            "current epoch: 2 / 4; current step: 5800 / 12500; loss = 2.0475\n",
            "current epoch: 2 / 4; current step: 5900 / 12500; loss = 1.3684\n",
            "current epoch: 2 / 4; current step: 6000 / 12500; loss = 1.8588\n",
            "current epoch: 2 / 4; current step: 6100 / 12500; loss = 1.9212\n",
            "current epoch: 2 / 4; current step: 6200 / 12500; loss = 2.2157\n",
            "current epoch: 2 / 4; current step: 6300 / 12500; loss = 1.6541\n",
            "current epoch: 2 / 4; current step: 6400 / 12500; loss = 2.1952\n",
            "current epoch: 2 / 4; current step: 6500 / 12500; loss = 1.2198\n",
            "current epoch: 2 / 4; current step: 6600 / 12500; loss = 1.5908\n",
            "current epoch: 2 / 4; current step: 6700 / 12500; loss = 2.3332\n",
            "current epoch: 2 / 4; current step: 6800 / 12500; loss = 1.8545\n",
            "current epoch: 2 / 4; current step: 6900 / 12500; loss = 1.6730\n",
            "current epoch: 2 / 4; current step: 7000 / 12500; loss = 1.4746\n",
            "current epoch: 2 / 4; current step: 7100 / 12500; loss = 2.6881\n",
            "current epoch: 2 / 4; current step: 7200 / 12500; loss = 1.8278\n",
            "current epoch: 2 / 4; current step: 7300 / 12500; loss = 1.8885\n",
            "current epoch: 2 / 4; current step: 7400 / 12500; loss = 1.9471\n",
            "current epoch: 2 / 4; current step: 7500 / 12500; loss = 1.3651\n",
            "current epoch: 2 / 4; current step: 7600 / 12500; loss = 1.8025\n",
            "current epoch: 2 / 4; current step: 7700 / 12500; loss = 2.4615\n",
            "current epoch: 2 / 4; current step: 7800 / 12500; loss = 1.8521\n",
            "current epoch: 2 / 4; current step: 7900 / 12500; loss = 2.2326\n",
            "current epoch: 2 / 4; current step: 8000 / 12500; loss = 1.8020\n",
            "current epoch: 2 / 4; current step: 8100 / 12500; loss = 1.8858\n",
            "current epoch: 2 / 4; current step: 8200 / 12500; loss = 2.2228\n",
            "current epoch: 2 / 4; current step: 8300 / 12500; loss = 1.7949\n",
            "current epoch: 2 / 4; current step: 8400 / 12500; loss = 1.7216\n",
            "current epoch: 2 / 4; current step: 8500 / 12500; loss = 1.7297\n",
            "current epoch: 2 / 4; current step: 8600 / 12500; loss = 2.1211\n",
            "current epoch: 2 / 4; current step: 8700 / 12500; loss = 1.8242\n",
            "current epoch: 2 / 4; current step: 8800 / 12500; loss = 2.4792\n",
            "current epoch: 2 / 4; current step: 8900 / 12500; loss = 1.7286\n",
            "current epoch: 2 / 4; current step: 9000 / 12500; loss = 1.8943\n",
            "current epoch: 2 / 4; current step: 9100 / 12500; loss = 1.9387\n",
            "current epoch: 2 / 4; current step: 9200 / 12500; loss = 1.6199\n",
            "current epoch: 2 / 4; current step: 9300 / 12500; loss = 1.6228\n",
            "current epoch: 2 / 4; current step: 9400 / 12500; loss = 2.0067\n",
            "current epoch: 2 / 4; current step: 9500 / 12500; loss = 1.3929\n",
            "current epoch: 2 / 4; current step: 9600 / 12500; loss = 1.6698\n",
            "current epoch: 2 / 4; current step: 9700 / 12500; loss = 1.8691\n",
            "current epoch: 2 / 4; current step: 9800 / 12500; loss = 1.5511\n",
            "current epoch: 2 / 4; current step: 9900 / 12500; loss = 1.5739\n",
            "current epoch: 2 / 4; current step: 10000 / 12500; loss = 1.9677\n",
            "current epoch: 2 / 4; current step: 10100 / 12500; loss = 2.7652\n",
            "current epoch: 2 / 4; current step: 10200 / 12500; loss = 1.2590\n",
            "current epoch: 2 / 4; current step: 10300 / 12500; loss = 1.5150\n",
            "current epoch: 2 / 4; current step: 10400 / 12500; loss = 1.9262\n",
            "current epoch: 2 / 4; current step: 10500 / 12500; loss = 1.7133\n",
            "current epoch: 2 / 4; current step: 10600 / 12500; loss = 1.1640\n",
            "current epoch: 2 / 4; current step: 10700 / 12500; loss = 2.3315\n",
            "current epoch: 2 / 4; current step: 10800 / 12500; loss = 1.8491\n",
            "current epoch: 2 / 4; current step: 10900 / 12500; loss = 1.8296\n",
            "current epoch: 2 / 4; current step: 11000 / 12500; loss = 1.5603\n",
            "current epoch: 2 / 4; current step: 11100 / 12500; loss = 1.4959\n",
            "current epoch: 2 / 4; current step: 11200 / 12500; loss = 2.4587\n",
            "current epoch: 2 / 4; current step: 11300 / 12500; loss = 1.7564\n",
            "current epoch: 2 / 4; current step: 11400 / 12500; loss = 1.6166\n",
            "current epoch: 2 / 4; current step: 11500 / 12500; loss = 1.8694\n",
            "current epoch: 2 / 4; current step: 11600 / 12500; loss = 2.0245\n",
            "current epoch: 2 / 4; current step: 11700 / 12500; loss = 2.0178\n",
            "current epoch: 2 / 4; current step: 11800 / 12500; loss = 1.6435\n",
            "current epoch: 2 / 4; current step: 11900 / 12500; loss = 2.1894\n",
            "current epoch: 2 / 4; current step: 12000 / 12500; loss = 1.9534\n",
            "current epoch: 2 / 4; current step: 12100 / 12500; loss = 1.9888\n",
            "current epoch: 2 / 4; current step: 12200 / 12500; loss = 1.4101\n",
            "current epoch: 2 / 4; current step: 12300 / 12500; loss = 2.7580\n",
            "current epoch: 2 / 4; current step: 12400 / 12500; loss = 1.6141\n",
            "current epoch: 2 / 4; current step: 12500 / 12500; loss = 1.4329\n",
            "current epoch: 3 / 4; current step: 100 / 12500; loss = 2.1318\n",
            "current epoch: 3 / 4; current step: 200 / 12500; loss = 1.9016\n",
            "current epoch: 3 / 4; current step: 300 / 12500; loss = 1.8999\n",
            "current epoch: 3 / 4; current step: 400 / 12500; loss = 1.7612\n",
            "current epoch: 3 / 4; current step: 500 / 12500; loss = 1.5869\n",
            "current epoch: 3 / 4; current step: 600 / 12500; loss = 1.5953\n",
            "current epoch: 3 / 4; current step: 700 / 12500; loss = 1.6637\n",
            "current epoch: 3 / 4; current step: 800 / 12500; loss = 1.4157\n",
            "current epoch: 3 / 4; current step: 900 / 12500; loss = 1.9341\n",
            "current epoch: 3 / 4; current step: 1000 / 12500; loss = 1.5515\n",
            "current epoch: 3 / 4; current step: 1100 / 12500; loss = 2.2119\n",
            "current epoch: 3 / 4; current step: 1200 / 12500; loss = 2.5576\n",
            "current epoch: 3 / 4; current step: 1300 / 12500; loss = 2.3468\n",
            "current epoch: 3 / 4; current step: 1400 / 12500; loss = 2.2487\n",
            "current epoch: 3 / 4; current step: 1500 / 12500; loss = 1.9381\n",
            "current epoch: 3 / 4; current step: 1600 / 12500; loss = 1.4499\n",
            "current epoch: 3 / 4; current step: 1700 / 12500; loss = 1.8673\n",
            "current epoch: 3 / 4; current step: 1800 / 12500; loss = 1.7261\n",
            "current epoch: 3 / 4; current step: 1900 / 12500; loss = 1.1747\n",
            "current epoch: 3 / 4; current step: 2000 / 12500; loss = 1.8065\n",
            "current epoch: 3 / 4; current step: 2100 / 12500; loss = 1.6592\n",
            "current epoch: 3 / 4; current step: 2200 / 12500; loss = 2.0118\n",
            "current epoch: 3 / 4; current step: 2300 / 12500; loss = 2.3719\n",
            "current epoch: 3 / 4; current step: 2400 / 12500; loss = 1.7757\n",
            "current epoch: 3 / 4; current step: 2500 / 12500; loss = 1.3127\n",
            "current epoch: 3 / 4; current step: 2600 / 12500; loss = 1.6187\n",
            "current epoch: 3 / 4; current step: 2700 / 12500; loss = 1.5901\n",
            "current epoch: 3 / 4; current step: 2800 / 12500; loss = 1.7276\n",
            "current epoch: 3 / 4; current step: 2900 / 12500; loss = 1.7873\n",
            "current epoch: 3 / 4; current step: 3000 / 12500; loss = 1.3164\n",
            "current epoch: 3 / 4; current step: 3100 / 12500; loss = 1.3129\n",
            "current epoch: 3 / 4; current step: 3200 / 12500; loss = 1.4668\n",
            "current epoch: 3 / 4; current step: 3300 / 12500; loss = 1.7817\n",
            "current epoch: 3 / 4; current step: 3400 / 12500; loss = 1.6405\n",
            "current epoch: 3 / 4; current step: 3500 / 12500; loss = 2.0249\n",
            "current epoch: 3 / 4; current step: 3600 / 12500; loss = 1.8669\n",
            "current epoch: 3 / 4; current step: 3700 / 12500; loss = 1.4881\n",
            "current epoch: 3 / 4; current step: 3800 / 12500; loss = 2.1418\n",
            "current epoch: 3 / 4; current step: 3900 / 12500; loss = 1.2651\n",
            "current epoch: 3 / 4; current step: 4000 / 12500; loss = 2.7283\n",
            "current epoch: 3 / 4; current step: 4100 / 12500; loss = 1.2547\n",
            "current epoch: 3 / 4; current step: 4200 / 12500; loss = 1.5934\n",
            "current epoch: 3 / 4; current step: 4300 / 12500; loss = 2.2828\n",
            "current epoch: 3 / 4; current step: 4400 / 12500; loss = 1.5399\n",
            "current epoch: 3 / 4; current step: 4500 / 12500; loss = 1.9386\n",
            "current epoch: 3 / 4; current step: 4600 / 12500; loss = 1.4234\n",
            "current epoch: 3 / 4; current step: 4700 / 12500; loss = 1.5117\n",
            "current epoch: 3 / 4; current step: 4800 / 12500; loss = 1.6101\n",
            "current epoch: 3 / 4; current step: 4900 / 12500; loss = 1.7182\n",
            "current epoch: 3 / 4; current step: 5000 / 12500; loss = 2.0740\n",
            "current epoch: 3 / 4; current step: 5100 / 12500; loss = 1.9142\n",
            "current epoch: 3 / 4; current step: 5200 / 12500; loss = 1.0962\n",
            "current epoch: 3 / 4; current step: 5300 / 12500; loss = 1.8061\n",
            "current epoch: 3 / 4; current step: 5400 / 12500; loss = 1.7134\n",
            "current epoch: 3 / 4; current step: 5500 / 12500; loss = 0.9941\n",
            "current epoch: 3 / 4; current step: 5600 / 12500; loss = 2.0075\n",
            "current epoch: 3 / 4; current step: 5700 / 12500; loss = 1.5055\n",
            "current epoch: 3 / 4; current step: 5800 / 12500; loss = 1.3211\n",
            "current epoch: 3 / 4; current step: 5900 / 12500; loss = 1.2722\n",
            "current epoch: 3 / 4; current step: 6000 / 12500; loss = 1.4986\n",
            "current epoch: 3 / 4; current step: 6100 / 12500; loss = 1.1110\n",
            "current epoch: 3 / 4; current step: 6200 / 12500; loss = 1.5268\n",
            "current epoch: 3 / 4; current step: 6300 / 12500; loss = 2.2559\n",
            "current epoch: 3 / 4; current step: 6400 / 12500; loss = 1.8582\n",
            "current epoch: 3 / 4; current step: 6500 / 12500; loss = 1.5009\n",
            "current epoch: 3 / 4; current step: 6600 / 12500; loss = 1.1588\n",
            "current epoch: 3 / 4; current step: 6700 / 12500; loss = 1.0720\n",
            "current epoch: 3 / 4; current step: 6800 / 12500; loss = 1.5649\n",
            "current epoch: 3 / 4; current step: 6900 / 12500; loss = 1.7151\n",
            "current epoch: 3 / 4; current step: 7000 / 12500; loss = 1.2234\n",
            "current epoch: 3 / 4; current step: 7100 / 12500; loss = 1.2661\n",
            "current epoch: 3 / 4; current step: 7200 / 12500; loss = 1.3127\n",
            "current epoch: 3 / 4; current step: 7300 / 12500; loss = 1.8223\n",
            "current epoch: 3 / 4; current step: 7400 / 12500; loss = 1.7107\n",
            "current epoch: 3 / 4; current step: 7500 / 12500; loss = 1.4800\n",
            "current epoch: 3 / 4; current step: 7600 / 12500; loss = 0.9384\n",
            "current epoch: 3 / 4; current step: 7700 / 12500; loss = 1.2948\n",
            "current epoch: 3 / 4; current step: 7800 / 12500; loss = 2.1949\n",
            "current epoch: 3 / 4; current step: 7900 / 12500; loss = 1.9386\n",
            "current epoch: 3 / 4; current step: 8000 / 12500; loss = 1.1831\n",
            "current epoch: 3 / 4; current step: 8100 / 12500; loss = 2.0598\n",
            "current epoch: 3 / 4; current step: 8200 / 12500; loss = 1.3070\n",
            "current epoch: 3 / 4; current step: 8300 / 12500; loss = 1.8123\n",
            "current epoch: 3 / 4; current step: 8400 / 12500; loss = 1.6419\n",
            "current epoch: 3 / 4; current step: 8500 / 12500; loss = 1.0518\n",
            "current epoch: 3 / 4; current step: 8600 / 12500; loss = 1.8487\n",
            "current epoch: 3 / 4; current step: 8700 / 12500; loss = 1.4137\n",
            "current epoch: 3 / 4; current step: 8800 / 12500; loss = 2.2194\n",
            "current epoch: 3 / 4; current step: 8900 / 12500; loss = 1.7877\n",
            "current epoch: 3 / 4; current step: 9000 / 12500; loss = 2.6919\n",
            "current epoch: 3 / 4; current step: 9100 / 12500; loss = 1.0220\n",
            "current epoch: 3 / 4; current step: 9200 / 12500; loss = 1.6561\n",
            "current epoch: 3 / 4; current step: 9300 / 12500; loss = 1.7945\n",
            "current epoch: 3 / 4; current step: 9400 / 12500; loss = 1.7555\n",
            "current epoch: 3 / 4; current step: 9500 / 12500; loss = 1.5057\n",
            "current epoch: 3 / 4; current step: 9600 / 12500; loss = 1.6932\n",
            "current epoch: 3 / 4; current step: 9700 / 12500; loss = 1.0128\n",
            "current epoch: 3 / 4; current step: 9800 / 12500; loss = 1.5825\n",
            "current epoch: 3 / 4; current step: 9900 / 12500; loss = 1.7299\n",
            "current epoch: 3 / 4; current step: 10000 / 12500; loss = 1.3047\n",
            "current epoch: 3 / 4; current step: 10100 / 12500; loss = 1.3259\n",
            "current epoch: 3 / 4; current step: 10200 / 12500; loss = 2.4936\n",
            "current epoch: 3 / 4; current step: 10300 / 12500; loss = 1.0941\n",
            "current epoch: 3 / 4; current step: 10400 / 12500; loss = 1.7527\n",
            "current epoch: 3 / 4; current step: 10500 / 12500; loss = 0.9351\n",
            "current epoch: 3 / 4; current step: 10600 / 12500; loss = 0.8700\n",
            "current epoch: 3 / 4; current step: 10700 / 12500; loss = 0.9768\n",
            "current epoch: 3 / 4; current step: 10800 / 12500; loss = 1.1526\n",
            "current epoch: 3 / 4; current step: 10900 / 12500; loss = 2.3297\n",
            "current epoch: 3 / 4; current step: 11000 / 12500; loss = 1.6046\n",
            "current epoch: 3 / 4; current step: 11100 / 12500; loss = 1.7447\n",
            "current epoch: 3 / 4; current step: 11200 / 12500; loss = 1.7121\n",
            "current epoch: 3 / 4; current step: 11300 / 12500; loss = 1.6350\n",
            "current epoch: 3 / 4; current step: 11400 / 12500; loss = 1.8788\n",
            "current epoch: 3 / 4; current step: 11500 / 12500; loss = 1.4159\n",
            "current epoch: 3 / 4; current step: 11600 / 12500; loss = 1.8369\n",
            "current epoch: 3 / 4; current step: 11700 / 12500; loss = 1.8129\n",
            "current epoch: 3 / 4; current step: 11800 / 12500; loss = 1.1140\n",
            "current epoch: 3 / 4; current step: 11900 / 12500; loss = 1.9494\n",
            "current epoch: 3 / 4; current step: 12000 / 12500; loss = 2.2148\n",
            "current epoch: 3 / 4; current step: 12100 / 12500; loss = 1.6483\n",
            "current epoch: 3 / 4; current step: 12200 / 12500; loss = 1.8743\n",
            "current epoch: 3 / 4; current step: 12300 / 12500; loss = 1.5754\n",
            "current epoch: 3 / 4; current step: 12400 / 12500; loss = 1.6945\n",
            "current epoch: 3 / 4; current step: 12500 / 12500; loss = 1.7996\n",
            "current epoch: 4 / 4; current step: 100 / 12500; loss = 1.1108\n",
            "current epoch: 4 / 4; current step: 200 / 12500; loss = 0.8022\n",
            "current epoch: 4 / 4; current step: 300 / 12500; loss = 1.2548\n",
            "current epoch: 4 / 4; current step: 400 / 12500; loss = 2.2998\n",
            "current epoch: 4 / 4; current step: 500 / 12500; loss = 1.2385\n",
            "current epoch: 4 / 4; current step: 600 / 12500; loss = 1.1540\n",
            "current epoch: 4 / 4; current step: 700 / 12500; loss = 0.8725\n",
            "current epoch: 4 / 4; current step: 800 / 12500; loss = 1.5416\n",
            "current epoch: 4 / 4; current step: 900 / 12500; loss = 1.3508\n",
            "current epoch: 4 / 4; current step: 1000 / 12500; loss = 2.3130\n",
            "current epoch: 4 / 4; current step: 1100 / 12500; loss = 1.5864\n",
            "current epoch: 4 / 4; current step: 1200 / 12500; loss = 1.4778\n",
            "current epoch: 4 / 4; current step: 1300 / 12500; loss = 1.3259\n",
            "current epoch: 4 / 4; current step: 1400 / 12500; loss = 1.2111\n",
            "current epoch: 4 / 4; current step: 1500 / 12500; loss = 1.1128\n",
            "current epoch: 4 / 4; current step: 1600 / 12500; loss = 1.8874\n",
            "current epoch: 4 / 4; current step: 1700 / 12500; loss = 2.5521\n",
            "current epoch: 4 / 4; current step: 1800 / 12500; loss = 1.5938\n",
            "current epoch: 4 / 4; current step: 1900 / 12500; loss = 1.1164\n",
            "current epoch: 4 / 4; current step: 2000 / 12500; loss = 0.9666\n",
            "current epoch: 4 / 4; current step: 2100 / 12500; loss = 1.4072\n",
            "current epoch: 4 / 4; current step: 2200 / 12500; loss = 1.8040\n",
            "current epoch: 4 / 4; current step: 2300 / 12500; loss = 2.2313\n",
            "current epoch: 4 / 4; current step: 2400 / 12500; loss = 1.4314\n",
            "current epoch: 4 / 4; current step: 2500 / 12500; loss = 2.0714\n",
            "current epoch: 4 / 4; current step: 2600 / 12500; loss = 1.7354\n",
            "current epoch: 4 / 4; current step: 2700 / 12500; loss = 1.7656\n",
            "current epoch: 4 / 4; current step: 2800 / 12500; loss = 0.9088\n",
            "current epoch: 4 / 4; current step: 2900 / 12500; loss = 0.8159\n",
            "current epoch: 4 / 4; current step: 3000 / 12500; loss = 1.9300\n",
            "current epoch: 4 / 4; current step: 3100 / 12500; loss = 1.5373\n",
            "current epoch: 4 / 4; current step: 3200 / 12500; loss = 1.5808\n",
            "current epoch: 4 / 4; current step: 3300 / 12500; loss = 1.3605\n",
            "current epoch: 4 / 4; current step: 3400 / 12500; loss = 1.1900\n",
            "current epoch: 4 / 4; current step: 3500 / 12500; loss = 1.1753\n",
            "current epoch: 4 / 4; current step: 3600 / 12500; loss = 1.3862\n",
            "current epoch: 4 / 4; current step: 3700 / 12500; loss = 1.2725\n",
            "current epoch: 4 / 4; current step: 3800 / 12500; loss = 0.9953\n",
            "current epoch: 4 / 4; current step: 3900 / 12500; loss = 1.6024\n",
            "current epoch: 4 / 4; current step: 4000 / 12500; loss = 1.2028\n",
            "current epoch: 4 / 4; current step: 4100 / 12500; loss = 2.1307\n",
            "current epoch: 4 / 4; current step: 4200 / 12500; loss = 1.0179\n",
            "current epoch: 4 / 4; current step: 4300 / 12500; loss = 1.7831\n",
            "current epoch: 4 / 4; current step: 4400 / 12500; loss = 1.4845\n",
            "current epoch: 4 / 4; current step: 4500 / 12500; loss = 2.6321\n",
            "current epoch: 4 / 4; current step: 4600 / 12500; loss = 1.1899\n",
            "current epoch: 4 / 4; current step: 4700 / 12500; loss = 1.8954\n",
            "current epoch: 4 / 4; current step: 4800 / 12500; loss = 2.0037\n",
            "current epoch: 4 / 4; current step: 4900 / 12500; loss = 1.5549\n",
            "current epoch: 4 / 4; current step: 5000 / 12500; loss = 1.7086\n",
            "current epoch: 4 / 4; current step: 5100 / 12500; loss = 1.9969\n",
            "current epoch: 4 / 4; current step: 5200 / 12500; loss = 0.6400\n",
            "current epoch: 4 / 4; current step: 5300 / 12500; loss = 1.4365\n",
            "current epoch: 4 / 4; current step: 5400 / 12500; loss = 1.3025\n",
            "current epoch: 4 / 4; current step: 5500 / 12500; loss = 1.0198\n",
            "current epoch: 4 / 4; current step: 5600 / 12500; loss = 1.5045\n",
            "current epoch: 4 / 4; current step: 5700 / 12500; loss = 1.3520\n",
            "current epoch: 4 / 4; current step: 5800 / 12500; loss = 1.1609\n",
            "current epoch: 4 / 4; current step: 5900 / 12500; loss = 1.0580\n",
            "current epoch: 4 / 4; current step: 6000 / 12500; loss = 1.7250\n",
            "current epoch: 4 / 4; current step: 6100 / 12500; loss = 1.4584\n",
            "current epoch: 4 / 4; current step: 6200 / 12500; loss = 1.1527\n",
            "current epoch: 4 / 4; current step: 6300 / 12500; loss = 1.5758\n",
            "current epoch: 4 / 4; current step: 6400 / 12500; loss = 2.6141\n",
            "current epoch: 4 / 4; current step: 6500 / 12500; loss = 0.9383\n",
            "current epoch: 4 / 4; current step: 6600 / 12500; loss = 1.5460\n",
            "current epoch: 4 / 4; current step: 6700 / 12500; loss = 1.4499\n",
            "current epoch: 4 / 4; current step: 6800 / 12500; loss = 0.9574\n",
            "current epoch: 4 / 4; current step: 6900 / 12500; loss = 1.5780\n",
            "current epoch: 4 / 4; current step: 7000 / 12500; loss = 1.6082\n",
            "current epoch: 4 / 4; current step: 7100 / 12500; loss = 1.0800\n",
            "current epoch: 4 / 4; current step: 7200 / 12500; loss = 1.8293\n",
            "current epoch: 4 / 4; current step: 7300 / 12500; loss = 1.7454\n",
            "current epoch: 4 / 4; current step: 7400 / 12500; loss = 0.8141\n",
            "current epoch: 4 / 4; current step: 7500 / 12500; loss = 1.8297\n",
            "current epoch: 4 / 4; current step: 7600 / 12500; loss = 1.6781\n",
            "current epoch: 4 / 4; current step: 7700 / 12500; loss = 1.3137\n",
            "current epoch: 4 / 4; current step: 7800 / 12500; loss = 1.6115\n",
            "current epoch: 4 / 4; current step: 7900 / 12500; loss = 1.6909\n",
            "current epoch: 4 / 4; current step: 8000 / 12500; loss = 0.5863\n",
            "current epoch: 4 / 4; current step: 8100 / 12500; loss = 1.4984\n",
            "current epoch: 4 / 4; current step: 8200 / 12500; loss = 2.1413\n",
            "current epoch: 4 / 4; current step: 8300 / 12500; loss = 1.6323\n",
            "current epoch: 4 / 4; current step: 8400 / 12500; loss = 1.3953\n",
            "current epoch: 4 / 4; current step: 8500 / 12500; loss = 1.2212\n",
            "current epoch: 4 / 4; current step: 8600 / 12500; loss = 1.2279\n",
            "current epoch: 4 / 4; current step: 8700 / 12500; loss = 1.4879\n",
            "current epoch: 4 / 4; current step: 8800 / 12500; loss = 1.8775\n",
            "current epoch: 4 / 4; current step: 8900 / 12500; loss = 1.7213\n",
            "current epoch: 4 / 4; current step: 9000 / 12500; loss = 1.6436\n",
            "current epoch: 4 / 4; current step: 9100 / 12500; loss = 1.9998\n",
            "current epoch: 4 / 4; current step: 9200 / 12500; loss = 1.5365\n",
            "current epoch: 4 / 4; current step: 9300 / 12500; loss = 1.7431\n",
            "current epoch: 4 / 4; current step: 9400 / 12500; loss = 1.6235\n",
            "current epoch: 4 / 4; current step: 9500 / 12500; loss = 1.4056\n",
            "current epoch: 4 / 4; current step: 9600 / 12500; loss = 1.3245\n",
            "current epoch: 4 / 4; current step: 9700 / 12500; loss = 1.2413\n",
            "current epoch: 4 / 4; current step: 9800 / 12500; loss = 2.0477\n",
            "current epoch: 4 / 4; current step: 9900 / 12500; loss = 1.0055\n",
            "current epoch: 4 / 4; current step: 10000 / 12500; loss = 1.2933\n",
            "current epoch: 4 / 4; current step: 10100 / 12500; loss = 1.1277\n",
            "current epoch: 4 / 4; current step: 10200 / 12500; loss = 0.9814\n",
            "current epoch: 4 / 4; current step: 10300 / 12500; loss = 1.7321\n",
            "current epoch: 4 / 4; current step: 10400 / 12500; loss = 1.6160\n",
            "current epoch: 4 / 4; current step: 10500 / 12500; loss = 1.6142\n",
            "current epoch: 4 / 4; current step: 10600 / 12500; loss = 0.6342\n",
            "current epoch: 4 / 4; current step: 10700 / 12500; loss = 1.5348\n",
            "current epoch: 4 / 4; current step: 10800 / 12500; loss = 1.1535\n",
            "current epoch: 4 / 4; current step: 10900 / 12500; loss = 0.7042\n",
            "current epoch: 4 / 4; current step: 11000 / 12500; loss = 1.8177\n",
            "current epoch: 4 / 4; current step: 11100 / 12500; loss = 1.4573\n",
            "current epoch: 4 / 4; current step: 11200 / 12500; loss = 2.1396\n",
            "current epoch: 4 / 4; current step: 11300 / 12500; loss = 1.1275\n",
            "current epoch: 4 / 4; current step: 11400 / 12500; loss = 1.4438\n",
            "current epoch: 4 / 4; current step: 11500 / 12500; loss = 0.5600\n",
            "current epoch: 4 / 4; current step: 11600 / 12500; loss = 3.8524\n",
            "current epoch: 4 / 4; current step: 11700 / 12500; loss = 1.1851\n",
            "current epoch: 4 / 4; current step: 11800 / 12500; loss = 0.9356\n",
            "current epoch: 4 / 4; current step: 11900 / 12500; loss = 1.1241\n",
            "current epoch: 4 / 4; current step: 12000 / 12500; loss = 1.0090\n",
            "current epoch: 4 / 4; current step: 12100 / 12500; loss = 1.1332\n",
            "current epoch: 4 / 4; current step: 12200 / 12500; loss = 2.1522\n",
            "current epoch: 4 / 4; current step: 12300 / 12500; loss = 1.2282\n",
            "current epoch: 4 / 4; current step: 12400 / 12500; loss = 1.2146\n",
            "current epoch: 4 / 4; current step: 12500 / 12500; loss = 1.4395\n",
            "46.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "T8qwdL56L9mv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}